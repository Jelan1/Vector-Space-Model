{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbdb7abc",
   "metadata": {},
   "source": [
    "# Statistical Methods (in progress)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad27fb6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-23T20:37:09.502549Z",
     "start_time": "2022-04-23T20:37:09.480517Z"
    }
   },
   "source": [
    "### Contents\n",
    "1. [Motivations](#Motivations)\n",
    "1. [Defining a clearer space](#Defining-a-clearer-space)\n",
    "    1. [Defining Length](#Defining-length)\n",
    "        1. [L-1](#L-1)\n",
    "        1. [L-2](#L-2)\n",
    "    1. [What is Distance?](#Distance)\n",
    "        1. [Cosine](#Cosine)\n",
    "1. [Evaluation Update](#Quick-Evaluation-Update)\n",
    "1. [Nearest Neighbors](#Nearest-Neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e5a9578",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-23T19:56:09.247289Z",
     "start_time": "2022-04-23T19:55:51.090999Z"
    },
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "import vsm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "W = pd.read_csv('giga5.csv',index_col=0) #read in raw giga word dataset\n",
    "DATA_HOME = os.path.join('data/data', 'wordrelatedness')\n",
    "eval_df = pd.read_csv( # read in evaluation dataset\n",
    "    os.path.join(DATA_HOME, \"wordrelatedness-dev.csv\"))\n",
    "giga5 = pd.read_csv('giga5.csv',index_col=0)\n",
    "def distance2pred(pred_df): # haven't added these to vsm.py yet\n",
    "    lis = [-1*i for i in pred_df['prediction']]\n",
    "    pred_df['prediction'] = pd.Series(lis)\n",
    "    return pred_df\n",
    "def random_scorer(x1, x2):\n",
    "    return random.random()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e065818d",
   "metadata": {},
   "source": [
    "### Motivations\n",
    "We've seen how W, a set of w-dimensional word vectors derived from raw co-occurance counts seem to carry an interesting embedding space. This is our initial VSM. Let's apply some statistical thinking to this space and reweigh the matrix/dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c17dfc4",
   "metadata": {},
   "source": [
    "# Defining a clearer space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431da7ce",
   "metadata": {},
   "source": [
    "### Defining length\n",
    "#### L-1 norm, Magnitude \n",
    "If we want to treat the colorful embeddings in Tableau as true vectors, we'll have to define them so they're more appropriate in vector space. As of now, the identity of each embedding comes from the co-occurance values present in its components (the band widths). In the Trio viz, notice the summed co-occurance values are unique for each embedding.The Y-Axis for 'age' tops out at 500k while 'old' is almost twice as large. These values represent the embedding's *magnitude*, the the sum of absolute values. \n",
    "It might make sense to use magnitude, Length-1(L1), as our notion of length.\n",
    "- L-1\n",
    "\n",
    "$$\\|u\\|_{1} = {\\sum_{i=1}^{w} |{u_{i}|}}$$\n",
    "\n",
    "#### L-2 norm, Length\n",
    "Imagine, however, we're looking at two words that are roughly synonyms. How about 'cookie' and 'biscuit'? We can be idealistic and assume there's no noise for now. Since they share so many of the same usages, as we run along their rows and compare the two, we'd find the co-occurance values (band widths) to be pretty much the same at each component. However, they're **not** identical. If I wanted to dip a treat in tea, and asked a Brit to bring some biscuits, I might wind up with soggy Oreos. We want to capture and amplify these slight differences in usage. Instead of summing the co-occurances at face values, we'll sum the *squares* of each component and take the square root at the end. This notion of length, L-2, is also more compatible with statistical Least Squares methods and happens to be the standard Linear Algebra definition of vector length.\n",
    "- L-2  $$\\|u\\|_{2} = \\sqrt{\\sum_{i=1}^{w} u_{i}^{2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959ba0a2",
   "metadata": {},
   "source": [
    "### Defining Distance\n",
    "There are even more ways to think about distance. We could treat the space like our physical reality and use euclidean distance. There's the grid-like Manhattan distance, and probability-oriented KL divergence. The slew of options reflects what makes ML interesting but also why new problems can feel overwhelming. The decisions, from matrix design to hyperparameter choices, are not formulaic. Instead, they're informed by the domain and your downstream tasks. Since ours is to make meaningful vector comparisons, we want to start addressing the noise from common words. The cliff between high and medium usage dwarfes a lot of nuance. We can normalize the word vectors so the components are expressed as a percentage of its length (like comparing by per capita). Then we could just use euclidean distance to express space between normalized vectors.\n",
    "- Normalization of vector *u* with **w** components\n",
    "$$\\textbf{normalize}(u_w) =\n",
    "\\left[ \n",
    "  \\frac{u_{1}}{\\|u\\|_{2}}, \n",
    "  \\frac{u_{2}}{\\|u\\|_{2}}, \n",
    "  \\ldots \n",
    "  \\frac{u_{w}}{\\|u\\|_{2}} \n",
    " \\right]$$\n",
    "- Euclidean Distance between vectors *u* and *v*\n",
    " $$\\textbf{euclidean}(u, v) = \n",
    "\\sqrt{\\sum_{i=1}^{w}|u_{i} - v_{i}|^{2}}$$\n",
    " \n",
    "The end result is a space in which the components of our word vectors have more meaning, since they share a common reference. Moreover, instead of just length as an identity, the *orientation* of these vectors in euclidean space have meaning. We can sort of think of them as arrows in 3-D space pointing in different directions.\n",
    "\n",
    "### Cosine\n",
    "If you are more familiar with Linear Algebra, you might notice we can achieve the same effect in one transformation. We take the dot product of the two vectors (giving us euclidean-like orientation), control for length by dividing this value by the product of their norms (normalizing them). That's the cosine distance between the two. Instead of talking about how far apart things are, it makes more sense to talk about how similar they are. So we simply flip the script and subtract the result from 1.\n",
    "- CosineSim\n",
    "$$\\textbf{CosineSim}(u, v) = \n",
    "1 - \\frac{\\sum_{i=1}^{w} u_{i} \\cdot v_{i}}{\\|u\\|_{2} \\cdot \\|v\\|_{2}}$$\n",
    "\n",
    "### Summary\n",
    "I'll use the cosine similarity since it's more practical, but it's the same exact thing as normalizing and taking euclidean distance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65867c2",
   "metadata": {},
   "source": [
    "## Quick Evaluation Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "65d04450",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-23T20:35:17.547798Z",
     "start_time": "2022-04-23T20:35:09.643510Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VSM Score Percent: 27.76320615138188\n",
      "Random Score Percent: 2.4253955339491053\n",
      "Glimpse of how our VSM answered\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>relatedness score</th>\n",
       "      <th>vsm prediction</th>\n",
       "      <th>percent error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>action</td>\n",
       "      <td>involvement</td>\n",
       "      <td>0.686000</td>\n",
       "      <td>0.744897</td>\n",
       "      <td>5.889677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>action</td>\n",
       "      <td>operation</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.928016</td>\n",
       "      <td>26.801612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>action</td>\n",
       "      <td>physician</td>\n",
       "      <td>0.227454</td>\n",
       "      <td>0.838599</td>\n",
       "      <td>61.114498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>action</td>\n",
       "      <td>subway</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.854321</td>\n",
       "      <td>53.432081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>action</td>\n",
       "      <td>truck</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.874324</td>\n",
       "      <td>43.432430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>activity</td>\n",
       "      <td>activity</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>activity</td>\n",
       "      <td>attempt</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.561553</td>\n",
       "      <td>16.155269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>activity</td>\n",
       "      <td>event</td>\n",
       "      <td>0.778620</td>\n",
       "      <td>0.848844</td>\n",
       "      <td>7.022406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>activity</td>\n",
       "      <td>facility</td>\n",
       "      <td>0.502664</td>\n",
       "      <td>0.849441</td>\n",
       "      <td>34.677691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>activity</td>\n",
       "      <td>music</td>\n",
       "      <td>0.424702</td>\n",
       "      <td>0.901657</td>\n",
       "      <td>47.695560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>activity</td>\n",
       "      <td>skiing</td>\n",
       "      <td>0.618687</td>\n",
       "      <td>0.871394</td>\n",
       "      <td>25.270714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>activity</td>\n",
       "      <td>travel</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.725447</td>\n",
       "      <td>60.544666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>activity</td>\n",
       "      <td>travel</td>\n",
       "      <td>0.488229</td>\n",
       "      <td>0.725447</td>\n",
       "      <td>23.721738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>actor</td>\n",
       "      <td>actress</td>\n",
       "      <td>0.803341</td>\n",
       "      <td>0.978900</td>\n",
       "      <td>17.555898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>ad</td>\n",
       "      <td>bacon</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.677548</td>\n",
       "      <td>47.754778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>address</td>\n",
       "      <td>hail</td>\n",
       "      <td>0.583250</td>\n",
       "      <td>0.708433</td>\n",
       "      <td>12.518302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>adhesive</td>\n",
       "      <td>glue</td>\n",
       "      <td>0.911287</td>\n",
       "      <td>0.906724</td>\n",
       "      <td>0.456244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>administration</td>\n",
       "      <td>management</td>\n",
       "      <td>0.733000</td>\n",
       "      <td>0.782560</td>\n",
       "      <td>4.956043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>admission</td>\n",
       "      <td>confession</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.881462</td>\n",
       "      <td>65.146169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>admission</td>\n",
       "      <td>ticket</td>\n",
       "      <td>0.763562</td>\n",
       "      <td>0.856735</td>\n",
       "      <td>9.317264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>admittance</td>\n",
       "      <td>right</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.821248</td>\n",
       "      <td>74.624817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>adult</td>\n",
       "      <td>doctor</td>\n",
       "      <td>0.450154</td>\n",
       "      <td>0.782886</td>\n",
       "      <td>33.273192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>adult</td>\n",
       "      <td>type</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.664691</td>\n",
       "      <td>64.469109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>advance</td>\n",
       "      <td>gone</td>\n",
       "      <td>0.095000</td>\n",
       "      <td>0.649655</td>\n",
       "      <td>55.465544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>advance</td>\n",
       "      <td>propose</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.773948</td>\n",
       "      <td>53.394802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>advance</td>\n",
       "      <td>recovery</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.816396</td>\n",
       "      <td>77.639623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>advantage</td>\n",
       "      <td>profit</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.708810</td>\n",
       "      <td>1.118991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>adventure</td>\n",
       "      <td>flood</td>\n",
       "      <td>0.313039</td>\n",
       "      <td>0.882424</td>\n",
       "      <td>56.938529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>adventure</td>\n",
       "      <td>rail</td>\n",
       "      <td>0.353448</td>\n",
       "      <td>0.849413</td>\n",
       "      <td>49.596454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>adventure</td>\n",
       "      <td>sixteen</td>\n",
       "      <td>0.041777</td>\n",
       "      <td>0.732799</td>\n",
       "      <td>69.102186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>advertisement</td>\n",
       "      <td>pond</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.816709</td>\n",
       "      <td>71.670921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word1        word2  relatedness score  vsm prediction  \\\n",
       "59          action  involvement           0.686000        0.744897   \n",
       "60          action    operation           0.660000        0.928016   \n",
       "61          action    physician           0.227454        0.838599   \n",
       "62          action       subway           0.320000        0.854321   \n",
       "63          action        truck           0.440000        0.874324   \n",
       "64        activity     activity           1.000000        1.000000   \n",
       "65        activity      attempt           0.400000        0.561553   \n",
       "66        activity        event           0.778620        0.848844   \n",
       "67        activity     facility           0.502664        0.849441   \n",
       "68        activity        music           0.424702        0.901657   \n",
       "69        activity       skiing           0.618687        0.871394   \n",
       "70        activity       travel           0.120000        0.725447   \n",
       "71        activity       travel           0.488229        0.725447   \n",
       "72           actor      actress           0.803341        0.978900   \n",
       "73              ad        bacon           0.200000        0.677548   \n",
       "74         address         hail           0.583250        0.708433   \n",
       "75        adhesive         glue           0.911287        0.906724   \n",
       "76  administration   management           0.733000        0.782560   \n",
       "77       admission   confession           0.230000        0.881462   \n",
       "78       admission       ticket           0.763562        0.856735   \n",
       "79      admittance        right           0.075000        0.821248   \n",
       "80           adult       doctor           0.450154        0.782886   \n",
       "81           adult         type           0.020000        0.664691   \n",
       "82         advance         gone           0.095000        0.649655   \n",
       "83         advance      propose           0.240000        0.773948   \n",
       "84         advance     recovery           0.040000        0.816396   \n",
       "85       advantage       profit           0.720000        0.708810   \n",
       "86       adventure        flood           0.313039        0.882424   \n",
       "87       adventure         rail           0.353448        0.849413   \n",
       "88       adventure      sixteen           0.041777        0.732799   \n",
       "89   advertisement         pond           0.100000        0.816709   \n",
       "\n",
       "    percent error  \n",
       "59       5.889677  \n",
       "60      26.801612  \n",
       "61      61.114498  \n",
       "62      53.432081  \n",
       "63      43.432430  \n",
       "64       0.000000  \n",
       "65      16.155269  \n",
       "66       7.022406  \n",
       "67      34.677691  \n",
       "68      47.695560  \n",
       "69      25.270714  \n",
       "70      60.544666  \n",
       "71      23.721738  \n",
       "72      17.555898  \n",
       "73      47.754778  \n",
       "74      12.518302  \n",
       "75       0.456244  \n",
       "76       4.956043  \n",
       "77      65.146169  \n",
       "78       9.317264  \n",
       "79      74.624817  \n",
       "80      33.273192  \n",
       "81      64.469109  \n",
       "82      55.465544  \n",
       "83      53.394802  \n",
       "84      77.639623  \n",
       "85       1.118991  \n",
       "86      56.938529  \n",
       "87      49.596454  \n",
       "88      69.102186  \n",
       "89      71.670921  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df, score = vsm.word_relatedness_evaluation(eval_df, giga5, distfunc=vsm.cosine)\n",
    "random_pred_df, random_score = vsm.word_relatedness_evaluation(eval_df, giga5, distfunc=random_scorer)\n",
    "pred_df = distance2pred(pred_df)\n",
    "pred_df['prediction'] = abs(1 - pred_df['prediction'])\n",
    "pred_df['percent error'] = abs(pred_df['score']-pred_df['prediction'])*100\n",
    "pred_df.rename(columns={'score': 'relatedness score'},inplace=True)\n",
    "pred_df.rename(columns={'prediction': 'vsm prediction'},inplace=True)\n",
    "print(f'VSM Score Percent: {score*100}')\n",
    "print(f'Random Score Percent: {random_score*-100}')\n",
    "print('Glimpse of how our VSM answered')\n",
    "pred_df[59:90]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4648ffd4",
   "metadata": {},
   "source": [
    "The significant jump in score from blind guessing reflects the basic meaning these word embedding take on in a well-defined space. Scrolling through shows it has begun capturing some basic connections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00db118a",
   "metadata": {},
   "source": [
    "###  Nearest Neighbors\n",
    "Since our vectors have meaningful orientation now, we can start doing what Semantle (https://semantle.novalis.org/) does. We can search for a word in our VSM and inspect the embeddings that are closest to it! Our hope is that words sharing a local space have something in common. It's a quick way to get a glimpse of what the landscape looks like. Nearest neighbors for various Age and Beauty are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4d992525",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-23T20:31:30.289543Z",
     "start_time": "2022-04-23T20:31:26.060072Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>university</th>\n",
       "      <td>0.043850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expense</th>\n",
       "      <td>0.046830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>risk</th>\n",
       "      <td>0.046907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>length</th>\n",
       "      <td>0.052734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>height</th>\n",
       "      <td>0.061168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gathering</th>\n",
       "      <td>0.065073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saint</th>\n",
       "      <td>0.069794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peak</th>\n",
       "      <td>0.077287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>level</th>\n",
       "      <td>0.077732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0\n",
       "age         0.000000\n",
       "university  0.043850\n",
       "expense     0.046830\n",
       "risk        0.046907\n",
       "length      0.052734\n",
       "height      0.061168\n",
       "gathering   0.065073\n",
       "saint       0.069794\n",
       "peak        0.077287\n",
       "level       0.077732"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(vsm.neighbors('age',(W))).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cceba34e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-23T20:32:05.696623Z",
     "start_time": "2022-04-23T20:32:01.561411Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beauty</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>integrity</th>\n",
       "      <td>0.023809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>architecture</th>\n",
       "      <td>0.024793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>makeup</th>\n",
       "      <td>0.025417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freshness</th>\n",
       "      <td>0.026953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brightness</th>\n",
       "      <td>0.027701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flavor</th>\n",
       "      <td>0.032795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>culture</th>\n",
       "      <td>0.033562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coldness</th>\n",
       "      <td>0.033635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glass</th>\n",
       "      <td>0.034652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0\n",
       "beauty        0.000000\n",
       "integrity     0.023809\n",
       "architecture  0.024793\n",
       "makeup        0.025417\n",
       "freshness     0.026953\n",
       "brightness    0.027701\n",
       "flavor        0.032795\n",
       "culture       0.033562\n",
       "coldness      0.033635\n",
       "glass         0.034652"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(vsm.neighbors('beauty',(W))).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e285991",
   "metadata": {},
   "source": [
    "The closest words for each concept are the not exactly inspiring. We address this in the next notebook, *Leveraging Probability*.\n",
    "\n",
    "Here's a sneak peak at at where this work will take us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b6922835",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-23T20:31:51.750004Z",
     "start_time": "2022-04-23T20:31:41.421698Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ages</th>\n",
       "      <td>0.600080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>0.702292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>older</th>\n",
       "      <td>0.705287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aged</th>\n",
       "      <td>0.716830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>women</th>\n",
       "      <td>0.717285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>young</th>\n",
       "      <td>0.721127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generation</th>\n",
       "      <td>0.721446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>younger</th>\n",
       "      <td>0.724120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adults</th>\n",
       "      <td>0.735210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0\n",
       "age         0.000000\n",
       "ages        0.600080\n",
       "gender      0.702292\n",
       "older       0.705287\n",
       "aged        0.716830\n",
       "women       0.717285\n",
       "young       0.721127\n",
       "generation  0.721446\n",
       "younger     0.724120\n",
       "adults      0.735210"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(vsm.neighbors('age',vsm.pmi(W))).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6347ceb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-23T20:32:01.556385Z",
     "start_time": "2022-04-23T20:31:51.754005Z"
    },
    "scrolled": true,
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beauty</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beautiful</th>\n",
       "      <td>0.523039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gorgeous</th>\n",
       "      <td>0.555254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>style</th>\n",
       "      <td>0.573829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fashion</th>\n",
       "      <td>0.584708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>romance</th>\n",
       "      <td>0.587333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>romantic</th>\n",
       "      <td>0.591599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lovely</th>\n",
       "      <td>0.596409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fantasy</th>\n",
       "      <td>0.606127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>colors</th>\n",
       "      <td>0.606353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "beauty     0.000000\n",
       "beautiful  0.523039\n",
       "gorgeous   0.555254\n",
       "style      0.573829\n",
       "fashion    0.584708\n",
       "romance    0.587333\n",
       "romantic   0.591599\n",
       "lovely     0.596409\n",
       "fantasy    0.606127\n",
       "colors     0.606353"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(vsm.neighbors('beauty',vsm.pmi(W))).head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
